\documentclass[twoside, 11pt]{article}

\usepackage[preprint]{jmlr2e}

\usepackage{natbib}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}

% for bayesian network diagrams
% ref: https://github.com/jluttine/tikz-bayesnet
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{bayesnet}

% ensure sufficient marginspace for todos
\setlength {\marginparwidth }{2cm}
\usepackage[obeyFinal]{todonotes}
% \setuptodonotes{inline}

% define notation for norm and abs that scale nicely.
% ref: https://tex.stackexchange.com/a/297263
\let\oldnorm\norm
\let\norm\undefined
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\let\oldabs\abs
\let\abs\undefined
\DeclarePairedDelimiter\abs{\lvert}{\rvert}

\DeclarePairedDelimiter\card{\lvert}{\rvert}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\gammad}{Gamma}
\DeclareMathOperator*{\poissond}{Poisson}
\DeclareMathOperator*{\negbind}{Neg-bin}

\newcommand{\reals}[0] {\mathbb{R}}
\newcommand{\nonnegint}[0] {\mathbb{N}_{\geq 0}}

\newcommand{\E}[0] {\mathbb{E}} %expect

\newcommand{\bigO}[0] {\mathcal{O}}

\newtheorem{thm}{Theorem}


\begin{document}

% style self-loop edges.
\tikzset{every loop/.style={min distance=10mm,in=60,out=120,looseness=10}}


\author{\name Reuben Fletcher-Costin}

\title{}

\maketitle

\begin{abstract}%
*DRAFT*

We consider a hidden Markov model for event counts with an additive Poisson noise term. The model is otherwise assumed to have a finite state space. Computing the posterior distrubtion is intractable. Instead, we define an approximation scheme for the posterior distribution by approximating the conditional posterior distribution for the Poisson rate parameter $\lambda$ with one scaled Gamma distribution per discrete state in the model's state space. We derive an approximate forward algorithm to advance approximate posterior one timestep. The approximate forward update algorithm minimises the KL-divergence from the true forward-updated approximate posterior distribution (in general, a mixture of Gamma distributions) to its projection back as a single Gamma distribution in the approximation space.
\end{abstract}

\section{Summary}

Here's the rough plan of attack:
\begin{enumerate}
\item define basic hidden Markov model
\item define hidden Markov model with Poisson noise
\item compute the likelihood for hidden Markov model with Poisson noise
\item follow \citet*{russell2002artificial} derivation of the forward update equation for the posterior
\item give a brief example illustrating why we need a way to encode belief of varying rates $\lambda$ for different states in the discrete space, to motivate approximations
\item make the working assumption that we can approximate the posterior distribution with $\gammad$ distributions, one for each hidden state $s \in S$ in the discrete state space.
\item note how this family of approximations are not closed under the transition operator on $S$ -- whenever we apply the transition operator we end up with a mixture of $\gammad$ distributions. Similarly for conditioning on evidence.
\item look for a best approximation of the resulting mixture within our approximation space, in the sense of minimal $KL$-divergence
\item derive closed-form equations for our approximation to project each mixture back down to a single $\gammad$ distribution
\item comment about approximation error
\end{enumerate}



\section{probabilistic model}
\subsection{Prelude: hidden Markov model}

Consider a first-order hidden Markov model (HMM) with a hidden state $x_t$ at each time $t=0,\ldots,T$ that generates observable evidence $z_t$ for $t=1,\ldots,T$. We use $z_{1:T}$ to denote $z_1, \ldots, z_T$. Due to the Markov assumptions, the joint distribution of $Z_{1:T}$ and $x_{0:T}$ factorises as
\begin{equation}
P(z_{1:T}, x_{0:T}) = P(x_0) \prod_{t=1, \ldots, T} P(z_t \mid x_t) P(x_t \mid x_{t-1} ) \; .
\end{equation}
The conditional dependence structure of the HMM is illustrated in Figure~\ref{fig:hmm}.Each hidden state $x_t$ takes values in a finite state space $S = \{ s_1, \ldots, s_n \}$. Each generated observation $z_t$ is an event count in $\nonnegint$. The probability of transitioning from a state $x_t=s_j$ at time $t$ to a state $x_{t+1}=s_i$ at time $t+1$ is given by
\begin{equation}
P(x_{t+1}=s^{\prime} \mid x_t=s) = A_{s^{\prime},s}
\end{equation}
where $A$ is an $n \times n$ stochastic matrix indexed by the hidden states of $S$. The probability of observing $z_t=k$ events at time $t$ is given by
\begin{equation}
P(z_t=k \mid x_t=s) = B_{k, s}
\end{equation}
where for $s \in S$ the column $B_s$ is a distribution for $k$ over $\nonnegint$.

% standard hmm

\begin{figure}[H]
\tikz{
	% nodes
	\node[latent] (x) {$x_t$}; %
	\node[latent,left=of x] (x0) {$x_0$}; %
	\node[obs,below=of x] (z) {$z_t$}; %
	% plates
	\plate {timeplate} {(x) (z)} {$T$};%
	% edges
	\edge {x0} {x}
	\edge {x} {z}
	% self-loop edges
	\path[->] (x) edge [loop above] node {$t=1,\ldots,T$; $t-1 \mapsto t$} ();
}
\caption{Hidden Markov model}
\label{fig:hmm}
\end{figure}

\subsection{Hidden Markov model with additive Poisson noise}

Now consider a HMM where the event count $z_t$, generated from the hidden state $x_t$, is no longer directly observable. Instead, at each time $t$ we observe an event count $y_t \in \nonnegint$ such that
\begin{equation}
y_t = x_t + k_t
\end{equation}
where $k_t \in \nonnegint$ is generated from a Poisson distribution with a rate $\lambda > 0$ that does not vary over time. We assume a prior distribution $\gammad(\alpha, \beta)$ over $\lambda$. The joint probability distribution for this model is assumed to be
\begin{align}
& P(y_{1:T}, z_{1:T}, x_{0:T}, k_{1:t}, \lambda, \alpha, \beta) \nonumber \\
= & P(x_0) P(\alpha, \beta) P(\lambda \mid \alpha, \beta) \prod_{t=1, \ldots, T} P(y_t \mid k_t, z_t) P(k_t \mid \lambda) P(z_t \mid x_t) P(x_t \mid x_{t-1} ) \; .
\end{align}
This conditional dependence structure is shown in Figure~\ref{fig:hmmpoisson}.

The likelihood $P(y_t=y \mid x_t, \alpha, \beta)$ of observing $y_t=y$ events given the latent variables $x_t, \alpha, \beta$ reduces to a discrete convolution between the likelihood of the noise-free HMM $P(z_t=k \mid x_t)$ and the likelihood of the noise model $P(k_t=k \mid \alpha, \beta)$.
\begin{align}
& P(y_t=y \mid x_t, \alpha, \beta) \nonumber \\
= & \int_{(z, k, \lambda)} P(y_t=y \mid x_t, \alpha, \beta, z_t=z, k_t=k, \lambda=\lambda) P(z_t=z, k_t=k, \lambda=\lambda \mid x_t, \alpha, \beta) \, d(z, k, \lambda) \nonumber \\
= & \int_{(z, k, \lambda)}
P(y_t=y \mid z_t=z, k_t=k)
P(z_t=z \mid x_t)
P(k_t=k \mid \lambda)
P(\lambda \mid \alpha, \beta)
\, d(z, k, \lambda) \nonumber \\
= & \int_{(k, \lambda)}
P(z_t=y-k \mid x_t)
P(k_t=k \mid \lambda)
P(\lambda \mid \alpha, \beta)
\, d(k, \lambda) \nonumber \\
= & \sum_{k \in \nonnegint} P(z_t = y-k \mid x_t)
\int_{\lambda} P(k_t = k \mid \lambda) P(\lambda \mid \alpha, \beta) \, d \lambda \, .
\end{align}
The choice of $P(k_t = k \mid \lambda)$ as the Poisson distribution and $P(\lambda \mid \alpha, \beta)$ as its conjugate prior Gamma distribution leads to a closed-form expression for the integral:
\begin{align}
& \int_{\lambda}
P(k_t = k \mid \lambda) P(\lambda \mid \alpha, \beta)
\, d \lambda \nonumber \\
= & \int_{\lambda}
\poissond( k ; \lambda) \gammad( \lambda ; \alpha, \beta)
\, d \lambda \nonumber \\
= &
\binom{\alpha+k-1}{k} \left( \frac{\beta}{\beta+1} \right)^{\alpha} \left( \frac{1}{\beta+1} \right)^{k} \, .
\end{align}
A short proof of this identity is given in Appendix~\ref{appendix:gammaconj}. This final expression is known~\citep{gelman2013bayesian} to be the negative binomial density $k \sim \negbind\left(\alpha, \beta\right)$. Combining the above two derivations produces a terse expression for the likelihood
\begin{align}
P(y_t=y \mid x_t, \alpha, \beta)
= & \sum_{k \in \nonnegint} P(z_t = y-k \mid x_t) \negbind\left(k ; \alpha, \beta\right) \, . \label{eqn:hybridconjpriorobs}
\end{align}

% hmm with additive Poisson noise

\begin{figure}
\tikz{
	% nodes
	\node[obs] (y) {$y_t$}; %
	\node[latent,above=of y] (z) {$z_t$}; %
	\node[latent,above left=of y] (k) {$k_t$}; %
	\node[latent,above=of z] (x) {$x_t$}; %
	\node[latent,left=of x, xshift=-1cm] (x0) {$x_0$}; %

	\node[latent,left=of k] (lambda) {$\lambda$}; %
	\node[latent,left=of lambda] (alphabeta) {$\alpha, \beta$}; %
	% plates
	\plate {timeplate} {(x) (z) (k) (y)} {$T$};%
	% edges
	\edge {x0} {x}
	\edge {x} {z}
	\edge {z} {y}
	\edge {k} {y}
	\edge {lambda} {k}
	\edge {alphabeta} {lambda}
	% self-loop edges
	\path[->] (x) edge [loop above] node {$t=1,\ldots,T$; $t-1 \mapsto t$} ();
}
\caption{Hidden Markov model with Poisson noise}
\label{fig:hmmpoisson}
\end{figure}

\subsection{Inference}
\subsection{Standard HMM inference tasks}

As explained by \citet{rabiner1989tutorial}, \citet*{russell2002artificial}, given a hidden Markov model, there are a number of standard inference tasks we may wish to perform:

\begin{enumerate}
\item ``filtering'': estimating the posterior distribution at the current time $t=T$ over latent variables given evidence to date $y_{1:t}$
\item ``smoothing'': estimating the posterior distribution over latent variables given the evience to date at some historical time $t<T$
\item ``prediction'': estimating the posterior distribution over latent variables at future times $t>T$ given evidence to date
\item most likely explanation: recovering a trajectory of latent states that is best, in some particular sense (e.g. via the Viterbi algorithm)
\item estimating or training the parameters of our Markov model (E.g. via the Baum-Welch algorithm, an instance of Expectation Maximisation algorithms).
\end{enumerate}

We will focus on the first task, ``filtering''.

\subsection{Forward update}

The goal is to derive a computationally tractable way to update the posterior of the latent variables $P(x_t, \lambda \mid y_{1:t})$ given the information from one new observation of an event count $y_{t+1}$. A suitable update would be some function $F$ expressing the following relation:
\begin{equation}
P(x_{t+1}, \lambda \mid y_{1:t+1}) = F\left( P(x_t, \lambda \mid y_{1:t}), y_{t+1}\right)
\end{equation}

Although the rate parameter $\lambda$ does not vary in time, it can be notationally helpful to write $(x_t, \lambda_t)$ to denote the random variables $x_t$ and $\lambda_t=\lambda$ at time $t$. We can regard $(x_t, \lambda_t)$ as the hidden state of a HMM on the product state space $S \times \reals_{>0}$, with a transition model defined naturally component-wise -- note the transition model for $\lambda_t$ is trivial since $\lambda_t=\lambda$ for all $t$.

We structure the derivation of the forward upate for the model's posterior distribution $P(x_{t+1}, \lambda_t \mid y_{1:{t+1}})$ following \citet*{russell2002artificial}:
\begin{align}
& P(x_{t+1}, \lambda_{t+1} \mid y_{1:{t+1}}) \nonumber \\
= & P(x_{t+1}, \lambda_{t+1} \mid y_{1:t}, y_{t+1}) \nonumber \\
= & P(y_{t+1} \mid y_{1:t})^{-1} P(y_{t+1} \mid x_{t+1}, \lambda_{t+1}, y_{1:t}) P(x_{t+1}, \lambda_{t+1} \mid y_{1:t}) \nonumber \\
= & P(y_{t+1} \mid y_{1:t})^{-1} P(y_{t+1} \mid x_{t+1}, \lambda_{t+1}) P(x_{t+1}, \lambda_{t+1} \mid y_{1:t}) , \label{eqn:rawforward}
\end{align}
which follows from Bayes' theorem and the conditional dependence structure of the model.

The first factor $P(y_{t+1} \mid y_{1:t})^{-1}$ does not depend upon our latent variables and can be dropped if we are only interested in estimating relative posterior probabilities for different $(x_t, \lambda)$. We retain this factor to keep us honest - later on we will need to perform careful normalisation. The second factor, the likelihood $P(y_{t+1} \mid x_{t+1}, \lambda_{t+1})$ is a discrete convolution between the noise-free HMM's observation model $P(z_{t+1}=w \mid x_{t+1}=s^{\prime}) = B_{k,s^{\prime}}$ and our noise model $P(k_t=w \mid \lambda_t) = \poissond(w ; \lambda_t)$, that is,
\begin{equation}
P(y_{t+1}=k \mid x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime})
=
\sum_{w \in \nonnegint} B_{k-w,s^{\prime}} \poissond(w ; \lambda^{\prime}) \, \label{eqn:hybridobs} .
\end{equation}
The latter factor $P(x_{t+1}, \lambda_{t+1} \mid y_{1:t})$ needs to be rewritten as a function of $P(x_{t}, \lambda_{t} \mid y_{1:t})$, which can be obtained from the transition model after conditioning on $x_t=s, \lambda_t=\lambda$:
\begin{align}
& P(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime} \mid y_{1:t}) \nonumber \\
= & \sum_{s \in S} \int_{\lambda \in \reals_{>0}}
P(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime} \mid y_{1:t}, x_t=s, \lambda_t=\lambda ) P(x_t=s, \lambda_t=\lambda \mid y_{1:t} ) \,d\lambda \nonumber \\
= & \sum_{s \in S} \int_{\lambda \in \reals_{>0}}
P(x_{t+1}=s^{\prime}, \mid x_t=s)
P(\lambda_{t+1}=\lambda^{\prime} \mid \lambda_t=\lambda ) P(x_t=s, \lambda_t=\lambda \mid y_{1:t} ) \,d\lambda \nonumber \\
= & \sum_{s \in S}
P(x_{t+1}=s^{\prime}, \mid x_t=s)
P(x_t=s, \lambda_t=\lambda^{\prime} \mid y_{1:t} ) \nonumber \\
= & \sum_{s \in S}
A_{s^{\prime}, s}
P(x_t=s, \lambda_t=\lambda^{\prime} \mid y_{1:t} ) \nonumber \\
\label{eqn:advance}
\end{align}

Combining equation~\ref{eqn:rawforward} with equation~\ref{eqn:advance} and the expression for the likelihood~\ref{eqn:hybridobs} gives
\begin{align}
& P(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime} \mid y_{1:{t+1}}) \nonumber \\
= &
\frac{1}{P(y_{t+1} \mid y_{1:t})}
\left[
\sum_{s \in S}
A_{s^{\prime}, s}
\sum_{w \in \nonnegint}
B_{k-w,s^{\prime}} \poissond(w ; \lambda^{\prime})
P(x_t=s, \lambda_t=\lambda^{\prime} \mid y_{1:t} )
\right] \label{eqn:exactfwdupdate}
\end{align}

One complication impeding exact computation of the posterior $P(x_{t+1}, \lambda_{t+1} \mid y_{1:t+1})$ is the coupling between the latent variables $\lambda_{t}$ and $x_{t}$ after conditioning on $y_{1:t}$. For a simple example of this, consider a state space $S$, consisting of two hidden states $s_1$ and $s_2$, equipped with observation models $P(z_t \mid x_t=s_1)$ and $P(z_t \mid x_t=s_2)$ such that $\E \left[ P(z_t \mid x_t=s_1) \right] = 1$ and $\E \left[ P(z_t \mid x_t=s_2) \right] = 2$. Assume transitions between $s_1$ and $s_2$ are impossible, but that we have very little prior knowledge about the magnitude of $\lambda$, the rate of the Poisson noise, or the initial state $x_0$. Suppose we observe event data $y_1, \ldots, y_T$ over a period of time, and learn that the average event count $\sum_{t=1}^T y_t \approx 3$.  Then if the system were dwelling in state $x_t=s_1$ we would infer that $\lambda \approx 2$, in order for the expected rate of ``signal'' event counts $Z_t$ and ``noise'' event counts $k_t$ to sum to give the observed event counts $y_t \approx 3$. Alternatively, if the system had occupied state $x_t=s_2$ we would infer that $\lambda \approx 1$. This means that an accurate representation of our posterior belief $P(x_{t+1}, \lambda_{t+1} \mid y_{1:t+1})$ needs to be rich enough to model coupling between $\lambda_{t+1}$ and $x_{t+1}$.

The previous example also serves to illustrate how the marginal posterior distribution for $\lambda$ can be multi-modal. This is also true for the conditional posterior distribution $P(\lambda_t \mid x_t=s, y_{1:t})$. Consider a singleton state space $S=\{s\}$ with an observation model $P(z_t \mid x_t=s)$ that emits an event count of $z_t=0$ or $z_t=100$ with uniform probability $1/2$. Suppose we have little prior knowledge about the noise rate $\lambda$. At $t=1$ we observe our first data $y_1=100$. We infer either $z_1=100$ hence $k_1=0$ or $z_1=0$ hence $k_1=100$. Therefore our conditional posterior belief for the noise rate $P(\lambda_1 \mid x_1=s, y_1)$ will be bimodal, having one mode near $\lambda=100$ and another mode near $\lambda=0$.

\subsection{Approximate forward updates of approximate posteriors}
We can regard the forward update of the posterior as $\phi_{t+1} = F \left( \phi_t, y_{t+1} \right)$ where the $\phi$ are abstract elements of some space $\Phi$ that is closed under application of the following operators:
\begin{enumerate}
\item a transition operator $T : \Phi \rightarrow \Phi$ that evolves the latent states forward one time step.
\item a condition-on-observation operator $O_y : \Phi \rightarrow \Phi$, where $y$ is a new observation.
\end{enumerate}
If we have $T$ and $\{O_y\}_{y}$ then we can define $F(\phi, y) = O_{y} \circ T (\phi)$. Instead of representing the posterior exactly, we can select some approximation space $\Phi$ such that $P(x_t, \lambda \mid y_{1:t} ) \approx \phi_t \in \Phi$.

An approximation scheme may also be able to handle the case where the approximation space $\Phi$ is \emph{not} closed under application of $T$ or $O_y$. Suppose there exists some enclosing space $\bar{\Phi} \supset \Phi$ such that $\bar{\Phi}$ is closed under application of $T$ and $O_y$. Then, provided we can define a projection operator $\Pi_{\Phi} : \bar{\Phi} \rightarrow \Phi$ that maps each element in $\bar{\Phi} \setminus \Phi$ to its ``best'' approximation in $\Phi$, we can then define an approximate forward update function $\tilde{F}(\circ, y): \Phi \rightarrow \Phi$ by
\begin{equation}
\tilde{F}(\phi, y) \coloneqq \Pi_{\Phi} \circ O_{y} \circ T (\phi) \, .
\end{equation}

A natural way to project onto an approximation space inside a larger space $\bar{\Phi}$ equipped with a distance metric $d_{\bar{\Phi}}$ is to find any point in the approximation space with minimal distance from the point $\phi \in \bar{\Phi} \setminus \Phi$ we wish to approximate:
\begin{equation}
\Pi_{\Phi}(\phi)
\coloneqq
\argmin_{\phi^{\prime} \in \Phi } d_{\bar{\Phi}}(\phi, \phi^{\prime})
\end{equation}
Our objects $\phi$ are distributions, so instead of a distance metric we will instead measure error in the sense of the the (directed) Kullbackâ€“Leibler divergence of the original distribution $\phi$ from the approximant:~\footnote{
We chose this direction as intuitively it feels more correct to evaluate the expectation of the relative entropy with respect to the orginal, not the approximation. But perhaps this is mistaken, or perhaps it doesn't matter.}
\begin{align}
\Pi^{KL}_{\Phi}(\phi)
\coloneqq &
\argmin_{\phi^{\prime} \in \Phi } D_{KL}(\phi \mid \mid \phi^{\prime}) \\
 = & \argmin_{\phi^{\prime} \in \Phi } \mathbb{E}_{\phi} \left[ \log \left( \frac{ \phi^{\prime}}{ \phi } \right) \right]
\end{align}



\subsection{Discrete approximation of rate parameter $\lambda$}

One simple approximation scheme is to fix a-priori $m$ different values of the noise rate parameter $\{ \lambda_1, \ldots, \lambda_m \} = \Lambda_m \subset \reals_{>0}$. Then, if the state space $S$ contains $n$ hidden states $s_1, \ldots, s_n$, we can reduce the model to a HMM over the $n \times m$ discrete state space $(s , \lambda_j ) \in S \times \Lambda_m$. One way to construct this is to consider $m$ trivial single-state HMMs for each value of $\lambda_j$, then combine them into a single HMM with state space $\{ \lambda_1, \ldots, \lambda_m \}$ but no possible transitions between distinct states by taking the disjoint union of their state spaces $\{ \lambda_j \}_j$, then take the product of the resulting HMM with the standard noise-free discrete HMM for our states $x_t \in S$.  A downside to this approach is that if we pick too few values of $m$ we may get a poor approximation, but as we pick more values of $m$, the cumulative computational effort to repeatedly apply the transition operator over $t = 1, \ldots, T$ while updating the approximate posterior is $ \bigO (T n^2 m ) $.

\subsection{Approximation with Gamma distributions}

The simple discrete approximation scheme described in the previous subsection required us to store $m$ non-negative values $P(x_t=s, \lambda=\lambda_j \mid y_t)$ for each $s$, $t$ in order to approximate the distribution $\lambda \sim P(x_t=s, \lambda \mid y_t)$. We may be able to approximate the distribution of $\lambda$ for fixed $x_t=s$, $t$ more compactly with an appropriately chosen parametrised family of distributions. One obvious choice to investigate is the conjugate prior distribution for $\lambda$, $\gammad(\alpha, \beta)$. This suggests the following approximation:
\begin{equation}
P\left(x_t=s, \lambda \mid y_{1:t} \right) \approx \phi(x_t=s, \lambda) \coloneqq \gammad(\lambda ; \alpha_{s,t}, \beta_{s,t}) P(x_t=s \mid y_{1:t} ) ,
\end{equation}
where we regard the Gamma distribution $\gammad(\lambda ; \alpha_{s,t}, \beta_{s,t})$ as an approximation to the posterior distribution for the rate conditioned on the hidden state: $P(\lambda | x_t=s, y_{1:t})$. With this approximation, we need only maintain three scalar values for each $s$, $t$:
\begin{enumerate}
\item $P(x_t=s \mid y_{1:t})$, the value of the marginal distribution,
\item $\alpha_{s,t}>0$, a shape parameter, and
\item $\beta_{s,t}>0$ a rate parameter.
\end{enumerate}

We define our approximation space $\Phi$ as
\begin{equation}
\Phi \coloneqq \left\{ \phi_{\alpha, \beta, \gamma} : \alpha = (\alpha_s)_s, \beta = (\beta_s)_s, \gamma = (\gamma_s)_s, \alpha_s > 0, \beta_s > 0, \gamma_s \geq 0, \sum_{s \in S} c_s = 1 \right\}
\end{equation}
where each element $\phi_{\alpha, \beta, \gamma} \in \Phi$ is a function $\phi_{\alpha, \beta, \gamma} : S \times \reals_{>0} \rightarrow \reals_{\geq 0}$ that acts on a state-rate pair $(s, \lambda)$ by
\begin{equation}
\phi_{\alpha, \beta, \gamma} (s, \lambda) \coloneqq \gamma_s \; \gammad(\lambda ; \alpha_s, \beta_s) .
\end{equation}

This approximation scheme compresses the storage requirements per time $t$ from $n m$ scalar values of the previous approximation scheme down to $3 n$ scalar values. This reduction in parameters comes at the cost of no longer being able to represent multi-modal behaviour of $\lambda \sim P(\lambda | x_t=s_i y_{1:t})$. This approximation retains the ability to represent different noise rates $\lambda$ coupled with different hidden states $s \in S$. We are not directly concerned about storage requirements, but a smaller state space hints at the possibility of reduced computational effort.

\subsection{Approximate forward update for Gamma distribution approximation}

Substituting approximations $\phi(x_t, \lambda_t)$ for the true posterior $p(x_t, \lambda_t \mid y_{1:t})$ into the forward update equation~\ref{eqn:exactfwdupdate} gives:
\begin{align}
& \phi(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime}) \nonumber \\
\approx &
\frac{1}{P(y_{t+1} \mid y_{1:t})}
\left[
\sum_{s \in S}
A_{s^{\prime}, s}
\sum_{w \in \nonnegint}
B_{k-w,s^{\prime}} \poissond(w ; \lambda^{\prime})
\phi(x_t=s, \lambda_t=\lambda^{\prime})
\right]  \, . \label{eqn:rawapproxupdate}
\end{align}
where $y_{t+1} = k$.
Expanding $\phi(x_t=s, \lambda_t=\lambda^{\prime}) \coloneqq \gamma_{s,t} \gammad(\lambda^{\prime} ; \alpha_{s,t}, \beta_{s,t})$ allows us to use an identity between the Poisson and conjugate-prior Gamma distributions to eliminate the Poisson pmf factor:
\begin{align}
\poissond(w ; \lambda^{\prime}) \phi(x_t=s, \lambda_t=\lambda^{\prime}) & = 
\gamma_{s,t} \poissond(w ; \lambda^{\prime}) \gammad(\lambda^{\prime} ; \alpha_{s,t}, \beta_{s,t}) \nonumber \\
& = \gamma_{s,t} \negbind(w ; \alpha_{s,t}, \beta_{s,t}) \gammad(\lambda^{\prime} ; \alpha_{s,t} + w, \beta_{s,t} + 1) \nonumber \\
\end{align}
The identity used above is:
\begin{equation}
\poissond(w ; \lambda) \gammad(\lambda ; \alpha, \beta) = 
\negbind(w ; \alpha, \beta)
\gammad(\lambda ; \alpha + w, \beta + 1) \, . \nonumber
\end{equation}
The proof of this identity is elementary given the definitions of the three distributions, see Appendix~\ref{appendix:gammaconj}.

To simplify notation, define the non-negative real-valued tensor $c_{s^{\prime}, s, w, k, t}$ as
\begin{equation}
c_{s^{\prime}, s, w, k, t} \coloneqq A_{s^{\prime}, s} B_{k-w, s^{\prime}} \gamma_{s,t} \negbind(w ; \alpha_{s,t}, \beta_{s,t}) \, .
\end{equation}

The right hand side of the update equation~\ref{eqn:rawapproxupdate} is seen to be a finite mixture of Gamma distributions with non-negative weights:
\begin{align}
& \phi(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime}) \nonumber \\
\approx &
\frac{1}{P(y_{t+1} \mid y_{1:t})}
\left[
\sum_{s \in S}
\sum_{w \in \nonnegint}
c_{s^{\prime}, s, w, k, t}
\gammad(\lambda^{\prime} ; \alpha_{s,t} + w, \beta_{s,t} + 1)
\right]  \, .
\end{align}
Since the right-hand side is a mixture of Gamma distributions, while the left hand side is but a single scaled Gamma distribution, the error involved in this approximation has the potential to be large.

The plan is to approximate this mixture of Gamma distributions with a single approximating Gamma distribution. Before we can proceed, we note the mixture may not be normalised. We need to factor the mixture into a normalised mixture of Gamma distributions, and a scaling coefficient. To normalise we first drop the factor $P(y_{t+1} \mid y_{1:t})^{-1}$ as it is irrelevant if we only seek to compute relative probabilities. Then, since summing the posterior distribution over $s^{\prime} \in S$ and integrating over $\lambda^{\prime} \in \reals_{>0}$ should give unity, we require a normalisation constant $Z > 0$ such that
\begin{equation}
\frac{1}{Z}
\sum_{s^{\prime} \in S}
\sum_{s \in S}
\sum_{w \in \nonnegint}
c_{s^{\prime}, s, w, k, t}
\int_{\lambda}
\gammad(\lambda^{\prime} ; \alpha_{s,t} + w, \beta_{s,t} + 1)
\,d\lambda = 1 \nonumber
\end{equation}
Each integral of a Gamma distribution evaluates to one, hence we define
\begin{equation}
Z \coloneqq 
\sum_{s^{\prime} \in S}
\sum_{s \in S}
\sum_{w \in \nonnegint}
c_{s^{\prime}, s, w, k, t} \, .
\end{equation}
Again simplifying notation, define the non-negative real valued tensor $c^{\prime}_{s^{\prime}, s, w, k, t}$ as
\begin{equation}
c^{\prime}_{s^{\prime}, s, w, k, t} \coloneqq \frac{1}{Z}
c_{s^{\prime}, s, w, k, t} \, .
\end{equation}
Similarly, for each $x_t=s^{\prime}$, we want to recover an approximation for the posterior distribution for $\lambda$ conditioned on $x_{t}=s^{\prime}$, and this distribution should also sum to unity, so we seek additional normalizing constants $Z_{t,s^{\prime}} > 0$ such that
\begin{equation}
\frac{1}{Z_{t,s^{\prime}}}
\sum_{s \in S}
\sum_{w \in \nonnegint}
c^{\prime}_{s^{\prime}, s, w, k, t}
\int_{\lambda}
\gammad(\lambda^{\prime} ; \alpha_{s,t} + w, \beta_{s,t} + 1)
\,d\lambda = 1 \nonumber
\end{equation}
Hence we normalise once more by defining
\begin{equation}
Z_{t,s^{\prime}}
\coloneqq
\sum_{s \in S}
\sum_{w \in \nonnegint}
c^{\prime}_{s^{\prime}, s, w, k, t}
\end{equation}
and defining another non-negative real valued tensor $c^{\prime\prime}_{s^{\prime}, s, w, k, t}$ as
\begin{equation}
c^{\prime\prime}_{s^{\prime}, s, w, k, t} \coloneqq \frac{1}{Z_{t, s^{\prime}}}
c^{\prime}_{s^{\prime}, s, w, k, t} \, .
\end{equation}
Recall our approximation for the posterior at the next timestep $t+1$ is assumed to have the form
\begin{equation}
\phi(x_{t+1}=s^{\prime}, \lambda_{t+1}=\lambda^{\prime}) \coloneqq \gamma_{s^{\prime},t+1} \gammad(\lambda^{\prime} ; \alpha_{s^{\prime},t+1}, \beta_{s^{\prime},t+1})
\end{equation}
Therefore the scaling coefficient must be
\begin{equation}
\gamma_{s^{\prime},t+1} = Z_{t,s^{\prime}} \, .
\end{equation}
The remaining task is to derive expressions for $(\alpha_{s^{\prime},t+1}, \beta_{s^{\prime},t+1})$, which we can achieve by application of the following theorem:

\begin{thm}
Let $p(\lambda)$ be a finite mixture of Gamma distributions,
\begin{equation}
p(\lambda) = \sum_j c_j \gammad(\lambda \mid \theta_j)
\end{equation}
such that $\sum_j c_j = 1$, $c_j \geq 0$ for all $j$, $\theta_j = (\alpha_j, \beta_j)$ with $\alpha_j > 0$, $\beta_j > 0$.
Let $q(\lambda \mid \theta)$ be a Gamma distribution
\begin{equation}
q(\lambda \mid \theta ) = \gammad(\lambda \mid \theta) \, .
\end{equation}
Then the best approximation of $p(\lambda)$ by $q(\lambda \mid \theta)$ in the sense of KL-divergence from $q$ to $p$,
\begin{equation}
\theta^{*} = \argmin_{\theta} \int_{\lambda} p(\lambda) \log \left( \frac{q(\lambda \mid \theta) }{ p(\lambda) } \right) \, d\lambda ,
\end{equation}
is characterised by $\theta^* = (\alpha^*, \beta^*)$ satisfying the constraints:
\begin{alignat}{3}
\E_q \left[ \lambda \right]
& = \frac{\alpha^*}{\beta^*}
&& = \sum_j c_j \left( \frac{\alpha_j}{\beta_j} \right)
&& = \E_p \left[ \lambda \right] \\
\E_q \left[ \log(\lambda) \right]
& = \psi(\alpha^*) - \log(\beta^*)
&& = \sum_j c_j \left( \psi(\alpha_j) - \log(\beta_j) \right)
&& = \E_p \left[ \log(\lambda) \right]
\end{alignat}
where $\psi$ denotes the digamma function.

\end{thm}
\begin{proof}

Define $L(\theta) : \reals_{>0} \times \reals_{>0} \rightarrow \reals_{\geq 0}$ as
\begin{equation}
L(\theta) \coloneqq 
\int_{\lambda} p(\lambda) \log \left( \frac{q(\lambda \mid \theta) }{ p(\lambda) } \right) \, d\lambda .
\end{equation}
Provided $L$ is sufficiently smooth, local extreme points of $L$ occur in the interior where the gradient vanishes, so set $\theta^*$ as
\begin{equation}
D_{\theta} L(\theta) \bigr \rvert_{\theta=\theta^*} = \bar{0}
\end{equation}
Provided the argument of the integral is sufficiently smooth, we can commute the gradient inside the integral:
\begin{align}
D_{\theta}
\int_{\lambda} p(\lambda) \log \left( \frac{q(\lambda \mid \theta) }{ p(\lambda) } \right) \, d\lambda
& =
\int_{\lambda}
D_{\theta}
\left[
p(\lambda) \log \left( \frac{q(\lambda \mid \theta) }{ p(\lambda) } \right)
\right] \, d\lambda \\
& =
\int_{\lambda}
p(\lambda)
\frac{p(\lambda)}{q(\lambda \mid \theta)}
\frac{1}{p(\lambda)}
D_{\theta} \left[ q(\lambda \mid \theta) \right]
\, d\lambda \\
& =
\int_{\lambda}
\frac{p(\lambda)}{q(\lambda \mid \theta)}
D_{\theta} \left[ q(\lambda \mid \theta) \right]
\, d\lambda
\end{align}
Hence the vanishing gradient of $L$ at $\theta^*$ can be expressed equivalently as the two constraints
\begin{align}
\int_{\lambda}
\frac{p(\lambda)}{q(\lambda \mid \theta)}
\frac{\partial}{\partial \alpha} \left[ q(\lambda \mid \theta) \right]
\, d\lambda \bigr \vert_{\theta=\theta^*} & = 0 \, , \\
\int_{\lambda}
\frac{p(\lambda)}{q(\lambda \mid \theta)}
\frac{\partial}{\partial \beta} \left[ q(\lambda \mid \theta) \right]
\, d\lambda \bigr \vert_{\theta=\theta^*} & = 0 \, .
\end{align}
The partial derivative of $q(\lambda \mid \theta)$ with respect to $\beta$ is
\begin{align}
\frac{\partial}{\partial \beta} q(\lambda \mid \theta)
= & 
\frac{\partial}{\partial \beta} \left( \frac{\beta^{\alpha}}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda} \right) \\
= &
(\alpha) \frac{\beta^{\alpha-1}}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda}
+ 
(-\lambda) \frac{\beta^{\alpha}}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda}
\\
= & \left( \frac{\alpha}{\beta} - \lambda \right) q(\lambda \mid \theta) \, .
\end{align}
Substituting back into the first constraint gives
\begin{equation}
\int_{\lambda}
\frac{p(\lambda)}{q(\lambda \mid \theta)}
\left( \frac{\alpha}{\beta} - \lambda \right) q(\lambda \mid \theta)
\, d\lambda \bigr \vert_{\theta=\theta^*} = 0 \, , \\
\end{equation}
so provided $q(\lambda \mid \theta)$ is nonzero we have
\begin{equation}
\int_{\lambda}
p(\lambda)
\left( \frac{\alpha}{\beta} - \lambda \right)
\, d\lambda \bigr \vert_{\theta=\theta^*} =
\int_{\lambda}
p(\lambda)
\left( \frac{\alpha^{*}}{\beta^{*}} - \lambda \right)
\, d\lambda =
0 \, ,
\end{equation}
which, combined with the property that expected value of any Gamma distribution $\gammad(\lambda \mid \alpha, \beta)$ is $\frac{\alpha}{\beta}$, gives the first characterising constraint upon $\theta^{*}$.

For the second characterising constraint, the partial derivative of $q(\lambda \mid \theta)$ with respect to $\alpha$ is
\begin{align}
\frac{\partial}{\partial \alpha} q(\lambda \mid \theta)
= & 
\frac{\partial}{\partial \alpha} \left( \frac{\beta^{\alpha}}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta \lambda} \right) \\
= & \left( \frac{-\Gamma^{\prime}(\alpha)}{\Gamma(\alpha)} + \log(\lambda) + \log(\beta) \right) q(\lambda \mid \theta) \, .
\end{align}
Substituting back into the second constraint gives
\begin{equation}
\int_{\lambda}
\frac{p(\lambda)}{q(\lambda \mid \theta)}
\left( \frac{-\Gamma^{\prime}(\alpha)}{\Gamma(\alpha)} + \log(\lambda) + \log(\beta) \right) q(\lambda \mid \theta)
\, d\lambda \bigr \vert_{\theta=\theta^*} = 0 \, , \\
\end{equation}
so again, provided $q(\lambda \mid \theta)$ is nonzero,
\begin{equation}
\int_{\lambda}
p(\lambda)
\left( \frac{-\Gamma^{\prime}(\alpha)}{\Gamma(\alpha)} + \log(\lambda) + \log(\beta) \right)
\, d\lambda \bigr \vert_{\theta=\theta^*} = 0 \, , \\
\end{equation}
which rearranges to
\begin{equation}
\int_{\lambda}
p(\lambda) \log(\lambda) \, d\lambda
=
\int_{\lambda}
p(\lambda)
\left( \frac{\Gamma^{\prime}(\alpha^*)}{\Gamma(\alpha^*)} - \log(\beta^*) \right)
\, d\lambda
\end{equation}
where the fraction $\frac{\Gamma^{\prime}(\alpha^*)}{\Gamma(\alpha^*)} = \psi(\alpha^*)$ is recognised as the digamma aka 0-th order polygamma function. Finally, we use the following standard identity for the expected value of $\log(\lambda)$ for a Gamma distribution,
\begin{equation}
\int_{\lambda}
\gammad(\lambda ; \alpha, \beta ) \log(\lambda) \, d\lambda = \psi(\alpha) - \log(\beta) \; .
\end{equation}
This gives the second characterising constraint upon $\theta^*$ in the statement of the theorem.

Apart from a lot of loose ends to check edge cases and give a convincing argument for why the alleged extreme point is a local minima, and in fact the global minimum, this completes a sketch of the proof.

\end{proof}



\subsection{todo}

\begin{enumerate}
\item restate exact update equation in more abstract form (finite linear combination of unnormalised phi functions)
\item comment that our approximation space may not be closed under this operation (done)
\item propose how to repair the situation by projecting back into the approximation space (done)
\item propose minimising the KL divergence from the finite mixture to the element of the approximation space (done)
\item sketch how we can minimise by taking the derivative and setting it to the zero vector (done)
\item plug in our definition of the approximation scheme from the previous subsection (done)
\item compute some partial derivatives (done)
\item do a little algebra and derive some pretty constraints that characterise a best approximation (done, roughly)
\item do a little more algebra to define explicit update equations for our approximation forward update
\item comment about computational cost
\item comment about approximation error
\end{enumerate}

\appendix

\section{Gamma distribution identities}
\label{appendix:gammaconj}

The Poisson distribution and its conjugate prior Gamma distribution produce a closed-form expression when multiplied together. This follows immediately from unpacking the definitions, rearranging some factors, and inserting suitable forms of the multiplicative identity:
\begin{align}
& P(k_t = k \mid \lambda) P(\lambda \mid \alpha, \beta)
\nonumber \\
= &
\poissond( k ; \lambda) \gammad( \lambda ; \alpha, \beta)
\nonumber \\
= &
\frac{\lambda^k e^{-\lambda}}{k!}
\frac{\beta^{\alpha}}{\Gamma(\alpha)}
\lambda^{\alpha-1} e^{-\beta \lambda}
\lambda \nonumber \\
= &
\frac{1}{k!}
\frac{\beta^{\alpha}}{\Gamma(\alpha)}
\lambda^{(\alpha+k)-1} e^{-(\beta+1) \lambda}
\nonumber \\
= &
\frac{\Gamma(\alpha+k)}{\Gamma(\alpha) k!}
\frac{\beta^{\alpha}}{(\beta+1)^{\alpha+k}}
\frac{(\beta+1)^{\alpha+k}}{\Gamma(\alpha+k)}
\lambda^{(\alpha+k)-1} e^{-(\beta+1) \lambda}
\nonumber \\
= &
\frac{\Gamma(\alpha+k)}{\Gamma(\alpha) k!}
\frac{\beta^{\alpha}}{(\beta+1)^{\alpha+k}}
\gammad(\lambda ; \alpha+k, \beta+1)
\nonumber \\
= &
\binom{\alpha+k-1}{k} \left( \frac{\beta}{\beta+1} \right)^{\alpha} \left( \frac{1}{\beta+1} \right)^{k}
\gammad(\lambda ; \alpha+k, \beta+1)
\nonumber \\
= &
\negbind(k ; \alpha, \beta)
\gammad(\lambda ; \alpha+k, \beta+1) \, .
\nonumber
\end{align}
The penultimate factor in front of the Gamma distribution is known~\citep{gelman2013bayesian} to be the negative binomial density $k \sim \negbind\left(\alpha, \beta\right)$. Note that the upper parameter of the binomial coefficient may be negative when $k=0$ and $\alpha < 1$ -- one way to interpret this is to consider the definition $\binom{n}{k} = n! (k! (n-k)!)^{-1}$ over non-negative integers $n$ and $k$, recall that the factorial is extended over complex numbers by $\Gamma$, where at integers $n$ $\Gamma(n) = (n-1)!$, then extend $\binom{n}{k}$ by redefining it as $\binom{n}{k} = \Gamma(n+1) (\Gamma(k+1) \Gamma(n-k+1))^{-1}$ .

This identity can also be used to give a closed-form expression for the integral: 
\begin{align}
& \int_{\lambda}
P(k_t = k \mid \lambda) P(\lambda \mid \alpha, \beta)
\, d \lambda \nonumber \\
= & \int_{\lambda}
\poissond( k ; \lambda) \gammad( \lambda ; \alpha, \beta)
\, d \lambda \nonumber \\
= & \negbind(k ; \alpha, \beta) \int_{\lambda}
\gammad(\lambda ; \alpha+k, \beta+1)
\, d \lambda \nonumber \\
= & \negbind(k ; \alpha, \beta) \nonumber
\end{align}
where $\gammad(\lambda ; \alpha+k, \beta+1)$ is a distribution over $\lambda$ and hence integrates to unity.

\bibliography{note}

\end{document}
